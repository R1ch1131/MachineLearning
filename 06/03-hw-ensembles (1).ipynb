{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашняя работа. Деревья решений.\n",
    "\n",
    "## Полезная литература\n",
    "\n",
    "- [Habrahabr: ODS деревья решений](https://habrahabr.ru/company/ods/blog/322534/#derevo-resheniy)\n",
    "- [ВМК МГУ семинары по решающим деревьям](99-extra__ml-course-msu-Sem04_trees.pdf)\n",
    "- [Sklearn Decision Trees](http://scikit-learn.org/stable/modules/tree.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Сравнение моделей деревьев\n",
    "\n",
    "В этом блоке вы сравните разные конфигурации композиций деревьев:\n",
    "- DecisionTree\n",
    "- Bagging\n",
    "- Bagging с другими настройками подбора признаков для разбиения\n",
    "- RandomForest\n",
    "\n",
    "Будем использовать [датасет с винишком](https://archive.ics.uci.edu/ml/datasets/wine+quality) - это задача то ли классификации то ли регресси - нужно предсказывать качество вина. Будем думать что это классификация.\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/en/thumb/7/7c/Lulz_Security.svg/300px-Lulz_Security.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Чтение данных (1 балла)\n",
    "\n",
    "Данные лежат как обычно в `'./data/winequality-red.csv.gz'`.\n",
    "\n",
    "- Прочитайте их с помощью pandas\n",
    "- нарисуйте countplot целевого признака `quality`.\n",
    "- Что вы думаете по поводу количества представителей каждого класса.\n",
    "- Разбейте данные на X и y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "\n",
    "# Прочитайте файл\n",
    "wine_data = pd.read_csv('winequality-red.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение countplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=wine_data, x='quality')\n",
    "plt.title('Distribution of Wine Quality')\n",
    "plt.show()\n",
    "\n",
    "# Разделение на X и y\n",
    "X = wine_data.drop('quality', axis=1)\n",
    "y = wine_data['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'По поводу распределения классов: Обычно наблюдается несбалансированное распределение - больше всего вин среднего качества (5-6), меньше всего - очень высокого и очень низкого качества.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Сравнение моделей (4 балла)\n",
    "\n",
    "Задача классификации. Все признаки уже числовые. Значит можно пробовать просто все модели и выбрать лучшую. Так и поступим, сделайте кросс валидацию на 5 фолдах, используя `sklearn.model_selection.KFold` как аргумент у `cross_val_score`. Метрика качества будет `accuracy`.\n",
    "\n",
    "Алгоритмы для тестирования:\n",
    "- KNeighborsClassifier с 10 соседями\n",
    "- KNeighborsClassifier с 10 соседями и масштабированием StandartScaler\n",
    "- RidgeClassifier\n",
    "- DecisionTreeClassifier \n",
    "- BaggingClassifier c 100 деревьев\n",
    "- BaggingClassifier с 100 деревьев и каждое дерево обучается только по половине случайно выбранных признаков (см аргументы)\n",
    "- RandomForestClassifier c 100 деревьев\n",
    "\n",
    "Выведите среднее значение метрики качества для каждого из классификаторов. \n",
    "\n",
    "**hint**: каждый следующий алгоритм, будет показывать качество лучше, чем предыдущий. Если у вас не так - то что-то вы делаете неправильно. Везде зафиксируйте random_state=42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline  # добавляем этот импорт\n",
    "\n",
    "# Создаем KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Список моделей\n",
    "models = {\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=10),\n",
    "    'KNN+Scaling': Pipeline([('scaler', StandardScaler()), \n",
    "                           ('knn', KNeighborsClassifier(n_neighbors=10))]),\n",
    "    'Ridge': RidgeClassifier(random_state=42),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42),\n",
    "    'Bagging': BaggingClassifier(n_estimators=100, random_state=42),\n",
    "    'Bagging_half_features': BaggingClassifier(n_estimators=100, \n",
    "                                             max_features=0.5,\n",
    "                                             random_state=42),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Оценка моделей\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
    "    print(f'{name}: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Расуждения (8 баллов)\n",
    "\n",
    "Ответьте на вопросы развернуто, можете полистать литературу:\n",
    "\n",
    "- почему наблюдается значимая разница в качестве у KNeighborsClassifier с масштабированием и без\n",
    "- почему масштабирование не важно для деревьев решений\n",
    "- почему бэггинг на половине признаков для каждого дерева дал качество предсказания больше, чем на всех? (а он дал!)\n",
    "- у какой модели наибольшей отклонение от среднего качества предсказаний? А почему??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Разница в качестве KNN с масштабированием и без объясняется тем, что KNN чувствителен к масштабу признаков. Без масштабирования признаки с большими значениями доминируют при расчете расстояний.\n",
    "Деревья решений нечувствительны к масштабированию, так как они работают с порядком значений при разбиении, а не с абсолютными величинами.\n",
    "Бэггинг на половине признаков дает лучшее качество из-за снижения корреляции между деревьями, что уменьшает переобучение.\n",
    "Наибольшее отклонение обычно у одиночного дерева решений, так как оно наиболее чувствительно к изменениям в данных.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Переобучение и Ко\n",
    "\n",
    "В последнем задании вы уже заметили, что случайный лес может вести себя немного нестабильно. В этом задании мы возьмем опять датасет MNIST(простите) и будем его решать деревьями. Почему мы взяли его? Потому что в нем фактически много разных признаков (значения пикселей в пространстве), а деревья строятся делая разбиения по признакам. Обычно на эти разбиения не обращают внимание, так как главное что тюнят - это глубина дереьвев, количество деревьев, а кучу других параметров обходят стороной, так как они \"неясные\". Попробуем прояснить их."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Загрузка датасета (1 балл)\n",
    "\n",
    "Загрузите датасет с помощью функции `sklearn.datasets.load_digits`. В нем будут 64px картинки в векторной форме.\n",
    "\n",
    "Нарисуйте первые 10 цифр в одной ячейке, чтобы было красиво."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Загрузка данных\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация первых 10 цифр\n",
    "fig, axes = plt.subplots(1, 10, figsize=(20, 2))\n",
    "for ax, image, label in zip(axes, digits.images[:10], digits.target[:10]):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r)\n",
    "    ax.set_title(f'Digit: {label}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Перебор классификаторов (3 балла)\n",
    "\n",
    "В этом задании вам снова придется перебрать несколько классификаторов, но теперь мы обратим внимание на другие гиперпараметры и их влияние на качество классификации, кстати опять `accuracy`.\n",
    "\n",
    "Сделайте кроссвалидацию на 10 фолдах, указав `cv=10` для следующих классификаторов:\n",
    "\n",
    "- DecisionTreeClassifier с параметрами по-умолчанию\n",
    "- BaggingClassifier с 100 деревьвев\n",
    "- BaggingClassifier с 100 деревьев, НО с ограничением на максимальное количество признаков, участвующих при обучении каждого из деревьев в $\\sqrt{N}$, где $N$ - это число признаков.\n",
    "- BaggingClassifier с 100 деревьев, НО с ограничением на количество признаков участвующих в разбиении для каждого из деревьев в $\\sqrt{N}$, где $N$ - это число признаков. Это отличается от предыдущей модели тем, где ограничивается `max_features`. Читайте документацию :trollface:\n",
    "- обычный случайный лес со 100 деревьями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "n_features = X.shape[1]\n",
    "max_features = int(np.sqrt(n_features))\n",
    "\n",
    "classifiers = {\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42),\n",
    "    'Bagging': BaggingClassifier(n_estimators=100, random_state=42),\n",
    "    'Bagging_sqrt_features': BaggingClassifier(\n",
    "        n_estimators=100,\n",
    "        max_features=max_features,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'Bagging_sqrt_split': BaggingClassifier(\n",
    "        estimator=DecisionTreeClassifier(max_features=max_features),\n",
    "        n_estimators=100,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "    print(f'{name}: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 В чём разница? (3 балла)\n",
    "\n",
    "Ответье на вопрос: \n",
    "\n",
    "Странно то как? Почему ограничение на количество признаков в разбиении дерева и ограничение в количестве признаков для построения каждого дерева в BaggingClasifier дало СОВСЕМ разный результат в качестве предсказания? В чем магия?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Количество деревьев (2 балла)\n",
    "\n",
    "Сделайте перебор количества деревьев для `RandomForestClassifier`. Сохраните качества кросс валидации на 10 фолдах для `[1,5,10,15,50,100,150,200,300]` количества деревьев. Нарисуйте график, где по оси x - количество деревьев, а по оси y - качество. При каком количестве деревьев получается самое хорошее качество?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees = [1, 5, 10, 15, 50, 100, 150, 200, 300]\n",
    "scores = []\n",
    "\n",
    "for n in n_trees:\n",
    "    rf = RandomForestClassifier(n_estimators=n, random_state=42)\n",
    "    score = cross_val_score(rf, X, y, cv=10, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_trees, scores, '-o')\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Random Forest Performance vs Number of Trees')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Количество признаков  (2 балла)\n",
    "\n",
    "Переберите теперь максимальное количество признаков для `RandomForestClassifier` на 100 деревьях, от 1 до 64 с шагом 5. Постройте график качества по кроссвалидации на 10 фолдах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Перебор максимального количества признаков для RandomForestClassifier на 100 деревьях\n",
    "max_features = list(range(1, 65, 5))\n",
    "scores = []\n",
    "for max_feature in max_features:\n",
    "    algorithm = RandomForestClassifier(n_estimators=100, max_features=max_feature)\n",
    "    scores_max_feature = cross_val_score(algorithm, digits.data, digits.target, cv=10)\n",
    "    scores.append(scores_max_feature.mean())\n",
    "\n",
    "# Нарисуйте график качества по кроссвалидации на 10 фолдах\n",
    "plt.plot(max_features, scores)\n",
    "plt.xlabel('Максимальное количество признаков')\n",
    "plt.ylabel('Качество')\n",
    "plt.title('Качество RandomForestClassifier по максимальному количеству признаков')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Вопросы по RandomForest (8 баллов)\n",
    "\n",
    "Ответьте на вопросы:\n",
    "\n",
    "- Что происходит с ростом числа деревьев у случайного леса. Можно ли просто всегда брать 5000 деревьев и быть счастливым?\n",
    "- Как зависит качество предсказания в дереве в зависимости от max_features?\n",
    "- Почему качество зависит от max_features?\n",
    "- Как глубина деревьев влияет на качество случайного леса?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С ростом числа деревьев:\n",
    "Качество обычно улучшается до определенного момента\n",
    "После этого улучшение незначительное\n",
    "Брать 5000 деревьев не всегда оптимально из-за:\n",
    "Увеличения времени обучения и предсказания\n",
    "Увеличения требований к памяти\n",
    "Незначительного прироста в качестве после определенного порога\n",
    "Зависимость от max_features:\n",
    "При малых значениях - модель может упустить важные паттерны\n",
    "При больших значениях - может быть переобучение\n",
    "Оптимальное значение обычно около sqrt(n_features)\n",
    "max_features влияет на качество потому что:\n",
    "Контролирует разнообразие деревьев\n",
    "Влияет на способность модели находить важные признаки\n",
    "Балансирует между обобщающей способностью и точностью\n",
    "Глубина деревьев влияет:\n",
    "Малая глубина - недообучение\n",
    "Большая глубина - переобучение\n",
    "Оптимальная глубина зависит от сложности данных и количества примеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://habrastorage.org/web/ad8/366/a44/ad8366a4469346c6b2e1306495b05d1a.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
